<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Body-Only Pose Analyzer</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <style>
        body { margin: 0; background: #000; color: #fff; font-family: sans-serif; display: flex; flex-direction: column; height: 100vh; overflow: hidden; }
        #v-container { flex: 1; position: relative; background: #111; display: flex; align-items: center; justify-content: center; }
        canvas { max-width: 100%; max-height: 100%; object-fit: contain; background: #000; }
        video { display: none; }
        #ui { background: #222; padding: 15px; display: grid; grid-template-columns: 1fr 1fr; gap: 10px; padding-bottom: env(safe-area-inset-bottom); border-top: 1px solid #444; }
        button, input { background: #444; color: #fff; border: 1px solid #666; padding: 12px; border-radius: 10px; font-size: 14px; -webkit-appearance: none; }
        #msg { position: absolute; top: 15px; left: 15px; background: rgba(0,0,0,0.8); padding: 10px; border-radius: 8px; z-index: 100; font-size: 12px; border: 1px solid #555; }
        .full { grid-column: span 2; }
        #recBtn.active { background: #a22; border-color: #f55; }
    </style>
</head>
<body>

    <div id="v-container">
        <div id="msg">AIãƒ¢ãƒ‡ãƒ«æº–å‚™ä¸­...</div>
        <video id="vid" playsinline muted></video>
        <canvas id="can"></canvas>
    </div>

    <div id="ui">
        <input type="file" id="f" accept="video/*" class="full">
        <button id="startBtn">â–¶ è§£æé–‹å§‹</button>
        <button id="recBtn">ğŸ’¾ éŒ²ç”»ã—ã¦ä¿å­˜</button>
        <div style="grid-column: span 2; display: flex; gap: 15px; align-items: center; background: #333; padding: 10px; border-radius: 8px;">
            <label style="font-size: 12px;">ã‚ºãƒ¼ãƒ </label>
            <input type="range" id="zs" min="0.1" max="1.0" step="0.05" value="0.4" style="flex: 1;">
            <span id="zoomVal">0.4</span>
        </div>
    </div>

    <script>
        const video = document.getElementById('vid');
        const canvas = document.getElementById('can');
        const ctx = canvas.getContext('2d');
        const msg = document.getElementById('msg');
        let detector, recorder, chunks = [];

        let lastSX = 0, lastSY = 0, velX = 0, velY = 0;
        const lerpAmount = 0.12; 

        // éª¨æ ¼æ¥ç¶š (é¡”ãƒ‘ãƒ¼ãƒ„ 0-4 ã‚’é™¤ã„ãŸ 5ä»¥é™ã‚’ä½¿ç”¨)
        const connections = [
            [5, 7], [7, 9], [6, 8], [8, 10], // è…•
            [5, 6], [5, 11], [6, 12], [11, 12], // èƒ´ä½“
            [11, 13], [13, 15], [12, 14], [14, 16] // è¶³
        ];

        async function init() {
            try {
                const model = poseDetection.SupportedModels.MoveNet;
                detector = await poseDetection.createDetector(model, {
                    modelType: poseDetection.movenet.modelType.SINGLEPOSE_THUNDER
                });
                msg.innerText = "âœ… æº–å‚™å®Œäº† (ä½“å¹¹ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãƒ»é¡”é™¤å¤–)";
            } catch (e) { msg.innerText = "âŒ AIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼"; }
        }

        document.getElementById('f').onchange = (e) => {
            video.src = URL.createObjectURL(e.target.files[0]);
        };

        async function render() {
            if (video.paused || video.ended) return;

            const poses = await detector.estimatePoses(video);
            const w = video.videoWidth;
            const h = video.videoHeight;
            canvas.width = w; canvas.height = h;

            const zoom = parseFloat(document.getElementById('zs').value);
            const sw = w * zoom; const sh = h * zoom;
            let targetSX = lastSX; let targetSY = lastSY;

            if (poses && poses.length > 0) {
                const kp = poses[0].keypoints;
                // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 5ç•ª(è‚©)ä»¥é™ã®ã¿ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°å¯¾è±¡ã«ã™ã‚‹
                const bodyKps = kp.slice(5).filter(k => k.score > 0.35);

                if (bodyKps.length > 0) {
                    const avgX = bodyKps.reduce((s, k) => s + k.x, 0) / bodyKps.length;
                    const avgY = bodyKps.reduce((s, k) => s + k.y, 0) / bodyKps.length;
                    
                    targetSX = Math.max(0, Math.min(avgX - sw / 2, w - sw));
                    targetSY = Math.max(0, Math.min(avgY - sh / 2, h - sh));
                    velX = targetSX - lastSX; velY = targetSY - lastSY;
                } else {
                    targetSX = Math.max(0, Math.min(lastSX + velX, w - sw));
                    targetSY = Math.max(0, Math.min(lastSY + velY, h - sh));
                    velX *= 0.95; velY *= 0.95;
                }
            }

            lastSX += (targetSX - lastSX) * lerpAmount;
            lastSY += (targetSY - lastSY) * lerpAmount;

            ctx.drawImage(video, lastSX, lastSY, sw, sh, 0, 0, w, h);

            if (poses && poses.length > 0) {
                const kp = poses[0].keypoints;
                const sX = w / sw; const sY = h / sh;

                ctx.strokeStyle = "#00FFFF"; ctx.lineWidth = 10; ctx.lineCap = "round";
                connections.forEach(([i, j]) => {
                    if (kp[i].score > 0.35 && kp[j].score > 0.35) {
                        ctx.beginPath();
                        ctx.moveTo((kp[i].x - lastSX) * sX, (kp[i].y - lastSY) * sY);
                        ctx.lineTo((kp[j].x - lastSX) * sX, (kp[j].y - lastSY) * sY);
                        ctx.stroke();
                    }
                });

                ctx.fillStyle = "#FF8800";
                kp.forEach((p, idx) => {
                    // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 5ç•ª(å·¦è‚©)ä»¥é™ã®ã¿æç”»
                    if (p.score > 0.35 && idx >= 5) {
                        const rx = (p.x - lastSX) * sX;
                        const ry = (p.y - lastSY) * sY;
                        ctx.beginPath(); ctx.arc(rx, ry, 12, 0, Math.PI * 2); ctx.fill();
                        ctx.strokeStyle = "#FFF"; ctx.lineWidth = 3; ctx.stroke();
                    }
                });
            }
            requestAnimationFrame(render);
        }

        document.getElementById('startBtn').onclick = () => { video.play(); render(); };

        document.getElementById('recBtn').onclick = (e) => {
            if (recorder?.state === 'recording') {
                recorder.stop();
                e.target.classList.remove('active');
                e.target.innerText = "ğŸ’¾ éŒ²ç”»ã—ã¦ä¿å­˜";
            } else {
                chunks = [];
                const stream = canvas.captureStream(30);
                const mimeType = ["video/mp4;codecs=avc1", "video/webm"].find(t => MediaRecorder.isTypeSupported(t));
                recorder = new MediaRecorder(stream, { mimeType });
                recorder.ondataavailable = ev => chunks.push(ev.data);
                recorder.onstop = () => {
                    const blob = new Blob(chunks, { type: recorder.mimeType });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a'); a.href = url;
                    a.download = `body_pose_${Date.now()}.mp4`;
                    a.click();
                };
                recorder.start();
                e.target.classList.add('active'); e.target.innerText = "ğŸ”´ åœæ­¢";
            }
        };

        init();
    </script>
</body>
</html>
