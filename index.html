<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>High-Precision Video Export</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <style>
        body { margin: 0; background: #000; color: #fff; font-family: sans-serif; display: flex; flex-direction: column; height: 100vh; overflow: hidden; }
        #v-container { flex: 1; position: relative; background: #111; display: flex; align-items: center; justify-content: center; }
        canvas { max-width: 100%; max-height: 100%; object-fit: contain; }
        video { display: none; }
        #ui { background: #222; padding: 15px; display: grid; grid-template-columns: 1fr 1fr; gap: 10px; padding-bottom: env(safe-area-inset-bottom); border-top: 1px solid #444; }
        button, input { background: #444; color: #fff; border: 1px solid #666; padding: 14px; border-radius: 12px; font-size: 14px; -webkit-appearance: none; }
        #msg { position: absolute; top: 15px; left: 15px; background: rgba(0,0,0,0.85); padding: 10px 15px; border-radius: 10px; z-index: 100; font-size: 12px; border: 1px solid #0ff; color: #0ff; }
        .full { grid-column: span 2; }
        #exportBtn { background: #055; border-color: #0ff; }
        #exportBtn.processing { background: #a50; border-color: #f00; pointer-events: none; }
    </style>
</head>
<body>

    <div id="v-container">
        <div id="msg">AIæº–å‚™ä¸­...</div>
        <video id="vid" playsinline muted></video>
        <canvas id="can"></canvas>
    </div>

    <div id="ui">
        <input type="file" id="f" accept="video/*" class="full">
        <button id="previewBtn">â–¶ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å†ç”Ÿ</button>
        <button id="exportBtn">ğŸ“¥ è§£æmp4ã‚’æ›¸ãå‡ºã—</button>
        <div style="grid-column: span 2; display: flex; gap: 15px; align-items: center; background: #333; padding: 12px; border-radius: 10px;">
            <label style="font-size: 12px; color: #aaa;">ZOOM</label>
            <input type="range" id="zs" min="0.1" max="1.0" step="0.05" value="0.4" style="flex: 1;">
            <span id="zoomVal" style="font-weight: bold; width: 35px;">0.4</span>
        </div>
    </div>

    <script>
        const video = document.getElementById('vid');
        const canvas = document.getElementById('can');
        const ctx = canvas.getContext('2d');
        const msg = document.getElementById('msg');
        let detector, recorder, chunks = [];
        
        let lastSX = 0, lastSY = 0, velX = 0, velY = 0;
        let smoothKps = []; 
        const kpSmoothing = 0.4;
        const connections = [[5,7],[7,9],[6,8],[8,10],[5,6],[5,11],[6,12],[11,12],[11,13],[13,15],[12,14],[14,16]];

        async function init() {
            detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, {
                modelType: poseDetection.movenet.modelType.SINGLEPOSE_THUNDER
            });
            msg.innerText = "READY: æ›¸ãå‡ºã—ãƒ¢ãƒ¼ãƒ‰";
        }

        document.getElementById('f').onchange = (e) => { video.src = URL.createObjectURL(e.target.files[0]); };
        document.getElementById('zs').oninput = (e) => { document.getElementById('zoomVal').innerText = e.target.value; };

        // 1ã‚³ãƒã‚’è§£æã—ã¦æç”»ã™ã‚‹å…±é€šé–¢æ•°
        async function processFrame() {
            const poses = await detector.estimatePoses(video);
            const w = video.videoWidth; const h = video.videoHeight;
            canvas.width = w; canvas.height = h;
            const zoom = parseFloat(document.getElementById('zs').value);
            const sw = w * zoom; const sh = h * zoom;

            if (poses && poses.length > 0) {
                const kp = poses[0].keypoints;
                if (smoothKps.length === 0) smoothKps = JSON.parse(JSON.stringify(kp));
                kp.forEach((p, i) => {
                    if (p.score > 0.2) {
                        smoothKps[i].x = (smoothKps[i].x * kpSmoothing) + (p.x * (1 - kpSmoothing));
                        smoothKps[i].y = (smoothKps[i].y * kpSmoothing) + (p.y * (1 - kpSmoothing));
                        smoothKps[i].score = p.score;
                    }
                });
                const bodyKps = smoothKps.slice(5).filter(k => k.score > 0.3);
                if (bodyKps.length > 0) {
                    const avgX = bodyKps.reduce((s, k) => s + k.x, 0) / bodyKps.length;
                    const avgY = bodyKps.reduce((s, k) => s + k.y, 0) / bodyKps.length;
                    const targetSX = Math.max(0, Math.min(avgX - sw / 2, w - sw));
                    const targetSY = Math.max(0, Math.min(avgY - sh / 2, h - sh));
                    lastSX += (targetSX - lastSX) * 0.15;
                    lastSY += (targetSY - lastSY) * 0.15;
                }
            }
            ctx.drawImage(video, lastSX, lastSY, sw, sh, 0, 0, w, h);
            const scale = w / sw;
            ctx.lineCap = "round"; ctx.lineJoin = "round";
            ctx.strokeStyle = "#00FFFF"; ctx.lineWidth = 14;
            connections.forEach(([i, j]) => {
                const p1 = smoothKps[i], p2 = smoothKps[j];
                if (p1.score > 0.3 && p2.score > 0.3) {
                    ctx.beginPath();
                    ctx.moveTo((p1.x - lastSX) * scale, (p1.y - lastSY) * scale);
                    ctx.lineTo((p2.x - lastSX) * scale, (p2.y - lastSY) * scale);
                    ctx.stroke();
                }
            });
            ctx.fillStyle = "#FF7700"; ctx.strokeStyle = "#FFFFFF"; ctx.lineWidth = 3;
            smoothKps.forEach((p, idx) => {
                if (idx >= 5 && p.score > 0.3) {
                    ctx.beginPath(); ctx.arc((p.x - lastSX)*scale, (p.y - lastSY)*scale, 12, 0, Math.PI*2);
                    ctx.fill(); ctx.stroke();
                }
            });
        }

        // --- ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¢ãƒ¼ãƒ‰ ---
        document.getElementById('previewBtn').onclick = () => {
            video.play();
            async function loop() {
                if(!video.paused && !video.ended) { await processFrame(); requestAnimationFrame(loop); }
            }
            loop();
        };

        // --- ç´”ç²‹æ›¸ãå‡ºã—ãƒ¢ãƒ¼ãƒ‰ (ã“ã“ãŒé‡è¦) ---
        document.getElementById('exportBtn').onclick = async () => {
            const btn = document.getElementById('exportBtn');
            btn.classList.add('processing');
            btn.innerText = "â³ è§£æä¸­...";
            
            chunks = [];
            video.pause();
            video.currentTime = 0; // æœ€åˆã«æˆ»ã™

            const stream = canvas.captureStream(0); // ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®ã‚­ãƒ£ãƒ—ãƒãƒ£
            const mimeType = ["video/mp4;codecs=avc1", "video/webm"].find(t => MediaRecorder.isTypeSupported(t));
            recorder = new MediaRecorder(stream, { mimeType, videoBitsPerSecond: 8000000 });
            
            recorder.ondataavailable = e => chunks.push(e.data);
            recorder.onstop = () => {
                const blob = new Blob(chunks, { type: recorder.mimeType });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a'); a.href = url;
                a.download = `perfect_analysis.mp4`; a.click();
                btn.classList.remove('processing');
                btn.innerText = "ğŸ“¥ è§£æmp4ã‚’æ›¸ãå‡ºã—";
                msg.innerText = "âœ… ä¿å­˜å®Œäº†";
            };

            recorder.start();

            // 1ã‚³ãƒãšã¤é€ã‚ŠãªãŒã‚‰è§£æï¼ˆé‡è¦ï¼šã“ã‚ŒãŒç´”ç²‹ãªè§£æå‹•ç”»ã‚’ä½œã‚‹ã‚³ãƒ„ï¼‰
            const duration = video.duration;
            const fps = 30;
            const totalFrames = duration * fps;
            
            for (let i = 0; i < totalFrames; i++) {
                video.currentTime = i / fps;
                // å‹•ç”»ã®èª­ã¿è¾¼ã¿å®Œäº†ã‚’å¾…æ©Ÿ
                await new Promise(resolve => {
                    const onSeeked = () => {
                        video.removeEventListener('seeked', onSeeked);
                        resolve();
                    };
                    video.addEventListener('seeked', onSeeked);
                });
                await processFrame();
                recorder.requestData(); // ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’éŒ²ç”»ã«å«ã‚ã‚‹
                msg.innerText = `è§£æä¸­: ${Math.round((i/totalFrames)*100)}%`;
            }

            recorder.stop();
        };

        init();
    </script>
</body>
</html>
