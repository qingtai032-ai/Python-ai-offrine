<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Smooth Pose Analyzer</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <style>
        body { margin: 0; background: #000; color: #fff; font-family: sans-serif; display: flex; flex-direction: column; height: 100vh; overflow: hidden; }
        #v-container { flex: 1; position: relative; background: #111; display: flex; align-items: center; justify-content: center; }
        canvas { max-width: 100%; max-height: 100%; object-fit: contain; }
        video { display: none; }
        #ui { background: #222; padding: 15px; display: grid; grid-template-columns: 1fr 1fr; gap: 8px; padding-bottom: env(safe-area-inset-bottom); }
        button, input { background: #444; color: #fff; border: 1px solid #666; padding: 12px; border-radius: 8px; font-size: 14px; }
        #msg { position: absolute; top: 10px; left: 10px; background: rgba(0,0,0,0.8); padding: 8px; border-radius: 4px; z-index: 10; font-size: 12px; }
    </style>
</head>
<body>
    <div id="v-container">
        <div id="msg">AIæº–å‚™ä¸­...</div>
        <video id="vid" playsinline muted></video>
        <canvas id="can"></canvas>
    </div>
    <div id="ui">
        <input type="file" id="f" accept="video/*" style="grid-column: span 2;">
        <button id="startBtn">è§£æé–‹å§‹</button>
        <button id="recBtn">éŒ²ç”»ä¿å­˜</button>
        <div style="grid-column: span 2; display: flex; gap: 10px; align-items: center;">
            <label>ã‚ºãƒ¼ãƒ å€ç‡: <input type="range" id="zs" min="0.1" max="1.0" step="0.05" value="0.4"></label>
            <span id="zoomVal">0.4</span>
        </div>
    </div>

    <script>
        const video = document.getElementById('vid');
        const canvas = document.getElementById('can');
        const ctx = canvas.getContext('2d');
        const msg = document.getElementById('msg');
        let detector, recorder, chunks = [];

        // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ç”¨å¤‰æ•°
        let lastSX = 0, lastSY = 0;
        let velX = 0, velY = 0; // é€Ÿåº¦ï¼ˆæ…£æ€§ç”¨ï¼‰
        const lerpAmount = 0.15; // æ»‘ã‚‰ã‹ã•ï¼ˆå°ã•ã„ã»ã©ã‚†ã£ãã‚Šè¿½å¾“ï¼‰

        // éª¨æ ¼ã®ç¹‹ãŒã‚Šå®šç¾©
        const connections = [
            [5, 7], [7, 9], [6, 8], [8, 10], // è…•
            [5, 6], [5, 11], [6, 12], [11, 12], // èƒ´ä½“
            [11, 13], [13, 15], [12, 14], [14, 16] // è¶³
        ];

        async function init() {
            const model = poseDetection.SupportedModels.MoveNet;
            detector = await poseDetection.createDetector(model);
            msg.innerText = "âœ… æº–å‚™å®Œäº†";
        }

        document.getElementById('f').onchange = (e) => {
            video.src = URL.createObjectURL(e.target.files[0]);
        };

        async function render() {
            if (video.paused || video.ended) return;
            const poses = await detector.estimatePoses(video);
            
            const w = video.videoWidth;
            const h = video.videoHeight;
            canvas.width = w; canvas.height = h;

            let targetSX = lastSX, targetSY = lastSY;
            const zoom = parseFloat(document.getElementById('zs').value);
            const sw = w * zoom, sh = h * zoom;

            if (poses.length > 0 && poses[0].keypoints.find(kp => kp.score > 0.3)) {
                // äººã‚’æ¤œçŸ¥ã§ããŸå ´åˆ
                const pose = poses[0];
                const keypoints = pose.keypoints;
                
                // å…¨é–¢ç¯€ã®å¹³å‡åº§æ¨™ã‚’ã‚»ãƒ³ã‚¿ãƒ¼ã«ã™ã‚‹ï¼ˆå®‰å®šåŒ–ï¼‰
                const validKps = keypoints.filter(k => k.score > 0.3);
                const avgX = validKps.reduce((s, k) => s + k.x, 0) / validKps.length;
                const avgY = validKps.reduce((s, k) => s + k.y, 0) / validKps.length;

                targetSX = Math.max(0, Math.min(avgX - sw / 2, w - sw));
                targetSY = Math.max(0, Math.min(avgY - sh / 2, h - sh));

                // é€Ÿåº¦ï¼ˆæ…£æ€§ï¼‰ã‚’è¨ˆç®—
                velX = targetSX - lastSX;
                velY = targetSY - lastSY;
            } else {
                // ãƒ­ã‚¹ãƒˆã—ãŸå ´åˆï¼šå‰å›ã®é€Ÿåº¦ã‚’ç¶­æŒã—ã¦ã€Œæ…£æ€§ã€ã§å‹•ã
                targetSX = Math.max(0, Math.min(lastSX + velX, w - sw));
                targetSY = Math.max(0, Math.min(lastSY + velY, h - sh));
                // å¾ã€…ã«æ¸›é€Ÿ
                velX *= 0.9; velY *= 0.9;
            }

            // ç·šå½¢è£œé–“(LERP)ã§ã‚¬ã‚¯ã¤ãã‚’æŠ‘ãˆã‚‹
            lastSX += (targetSX - lastSX) * lerpAmount;
            lastSY += (targetSY - lastSY) * lerpAmount;

            // æç”»
            ctx.drawImage(video, lastSX, lastSY, sw, sh, 0, 0, w, h);

            // ãƒœãƒ¼ãƒ³ã®æç”»
            if (poses.length > 0) {
                const kp = poses[0].keypoints;
                ctx.strokeStyle = "#00FF00"; ctx.lineWidth = 4;
                ctx.fillStyle = "#00FF00";

                connections.forEach(([i, j]) => {
                    if (kp[i].score > 0.3 && kp[j].score > 0.3) {
                        ctx.beginPath();
                        ctx.moveTo((kp[i].x - lastSX) * (w/sw), (kp[i].y - lastSY) * (h/sh));
                        ctx.lineTo((kp[j].x - lastSX) * (w/sw), (kp[j].y - lastSY) * (h/sh));
                        ctx.stroke();
                    }
                });
            }
            requestAnimationFrame(render);
        }

        document.getElementById('startBtn').onclick = () => { video.play(); render(); };
        init();

        // éŒ²ç”»æ©Ÿèƒ½ï¼ˆå‰å›ã¨åŒã˜ï¼‰
        document.getElementById('recBtn').onclick = (e) => {
            if (recorder?.state === 'recording') {
                recorder.stop(); e.target.innerText = "éŒ²ç”»ä¿å­˜";
            } else {
                chunks = [];
                const stream = canvas.captureStream(30);
                recorder = new MediaRecorder(stream, { mimeType: 'video/webm' });
                recorder.ondataavailable = ev => chunks.push(ev.data);
                recorder.onstop = () => {
                    const blob = new Blob(chunks, { type: 'video/mp4' });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a'); a.href = url; a.download = 'output.mp4'; a.click();
                };
                recorder.start(); e.target.innerText = "ğŸ”´ åœæ­¢";
            }
        };
    </script>
</body>
</html>

