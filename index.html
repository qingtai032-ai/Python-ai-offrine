<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Ultimate Pose Analyzer</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <style>
        body { margin: 0; background: #000; color: #fff; font-family: sans-serif; display: flex; flex-direction: column; height: 100vh; overflow: hidden; }
        #v-container { flex: 1; position: relative; background: #111; display: flex; align-items: center; justify-content: center; }
        canvas { max-width: 100%; max-height: 100%; object-fit: contain; background: #000; }
        video { display: none; }
        #ui { background: #222; padding: 15px; display: grid; grid-template-columns: 1fr 1fr; gap: 10px; padding-bottom: env(safe-area-inset-bottom); border-top: 1px solid #444; }
        button, input { background: #444; color: #fff; border: 1px solid #666; padding: 14px; border-radius: 12px; font-size: 14px; -webkit-appearance: none; }
        #msg { position: absolute; top: 15px; left: 15px; background: rgba(0,0,0,0.85); padding: 10px 15px; border-radius: 10px; z-index: 100; font-size: 12px; border: 1px solid #0ff; color: #0ff; }
        .full { grid-column: span 2; }
        #recBtn.active { background: #d22; box-shadow: 0 0 15px #f00; }
    </style>
</head>
<body>

    <div id="v-container">
        <div id="msg">AIé«˜ç²¾åº¦ã‚¨ãƒ³ã‚¸ãƒ³èµ·å‹•ä¸­...</div>
        <video id="vid" playsinline muted></video>
        <canvas id="can"></canvas>
    </div>

    <div id="ui">
        <input type="file" id="f" accept="video/*" class="full">
        <button id="startBtn" style="background: #252;">â–¶ è§£æé–‹å§‹</button>
        <button id="recBtn">ğŸ’¾ å‹•ç”»ã‚’ä¿å­˜</button>
        <div style="grid-column: span 2; display: flex; gap: 15px; align-items: center; background: #333; padding: 12px; border-radius: 10px;">
            <label style="font-size: 12px; color: #aaa;">ZOOM</label>
            <input type="range" id="zs" min="0.1" max="1.0" step="0.05" value="0.4" style="flex: 1;">
            <span id="zoomVal" style="font-weight: bold; width: 35px;">0.4</span>
        </div>
    </div>

    <script>
        const video = document.getElementById('vid');
        const canvas = document.getElementById('can');
        const ctx = canvas.getContext('2d');
        const msg = document.getElementById('msg');
        let detector, recorder, chunks = [];

        // è£œæ­£ãƒ»ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ç”¨ãƒ¡ãƒ¢ãƒª
        let lastSX = 0, lastSY = 0, velX = 0, velY = 0;
        let smoothKeypoints = []; // åº§æ¨™è£œé–“ç”¨
        const lerpAmount = 0.15; 
        const kpSmoothing = 0.5; // é–¢ç¯€ã®å‹•ãã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹ï¼ˆ0.1~0.9, å¤§ãã„ã»ã©æ»‘ã‚‰ã‹ï¼‰

        const connections = [
            [5, 7], [7, 9], [6, 8], [8, 10], // è…•
            [5, 6], [5, 11], [6, 12], [11, 12], // èƒ´ä½“
            [11, 13], [13, 15], [12, 14], [14, 16] // è¶³
        ];

        async function init() {
            try {
                const model = poseDetection.SupportedModels.MoveNet;
                detector = await poseDetection.createDetector(model, {
                    modelType: poseDetection.movenet.modelType.SINGLEPOSE_THUNDER,
                    enableSmoothing: true // ãƒ¢ãƒ‡ãƒ«å´ã®ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‚‚æœ‰åŠ¹åŒ–
                });
                msg.innerText = "READY: é«˜ç²¾åº¦ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æœ‰åŠ¹";
            } catch (e) { msg.innerText = "ERROR: AIåˆæœŸåŒ–å¤±æ•—"; }
        }

        document.getElementById('f').onchange = (e) => {
            video.src = URL.createObjectURL(e.target.files[0]);
        };

        document.getElementById('zs').oninput = (e) => {
            document.getElementById('zoomVal').innerText = e.target.value;
        };

        async function render() {
            if (video.paused || video.ended) return;

            const poses = await detector.estimatePoses(video);
            const w = video.videoWidth;
            const h = video.videoHeight;
            canvas.width = w; canvas.height = h;

            const zoom = parseFloat(document.getElementById('zs').value);
            const sw = w * zoom; const sh = h * zoom;
            let targetSX = lastSX; let targetSY = lastSY;

            if (poses && poses.length > 0) {
                const kp = poses[0].keypoints;
                
                // åˆå›ã®ã¿smoothKeypointsã‚’åˆæœŸåŒ–
                if (smoothKeypoints.length === 0) smoothKeypoints = JSON.parse(JSON.stringify(kp));

                // é–¢ç¯€åº§æ¨™ã®è£œæ­£ï¼ˆå‰ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã®åˆæˆï¼‰
                kp.forEach((p, i) => {
                    if (p.score > 0.2) {
                        smoothKeypoints[i].x = smoothKeypoints[i].x * kpSmoothing + p.x * (1 - kpSmoothing);
                        smoothKeypoints[i].y = smoothKeypoints[i].y * kpSmoothing + p.y * (1 - kpSmoothing);
                        smoothKeypoints[i].score = p.score;
                    }
                });

                const bodyKps = smoothKeypoints.slice(5).filter(k => k.score > 0.3);

                if (bodyKps.length > 0) {
                    const avgX = bodyKps.reduce((s, k) => s + k.x, 0) / bodyKps.length;
                    const avgY = bodyKps.reduce((s, k) => s + k.y, 0) / bodyKps.length;
                    targetSX = Math.max(0, Math.min(avgX - sw / 2, w - sw));
                    targetSY = Math.max(0, Math.min(avgY - sh / 2, h - sh));
                    velX = targetSX - lastSX; velY = targetSY - lastSY;
                } else {
                    targetSX = Math.max(0, Math.min(lastSX + velX, w - sw));
                    targetSY = Math.max(0, Math.min(lastSY + velY, h - sh));
                    velX *= 0.98; velY *= 0.98;
                }
            }

            lastSX += (targetSX - lastSX) * lerpAmount;
            lastSY += (targetSY - lastSY) * lerpAmount;

            // èƒŒæ™¯ï¼ˆã‚ºãƒ¼ãƒ ï¼‰æç”»
            ctx.drawImage(video, lastSX, lastSY, sw, sh, 0, 0, w, h);

            if (smoothKeypoints.length > 0) {
                const sX = w / sw; const sY = h / sh;

                // 1. éª¨æ ¼ï¼ˆå¤ªã„ã‚·ã‚¢ãƒ³ç·šï¼‰
                ctx.strokeStyle = "#00FFFF"; 
                ctx.lineWidth = 14; // ã•ã‚‰ã«å¤ªã
                ctx.lineCap = "round"; 
                ctx.lineJoin = "round"; // æ¥åˆéƒ¨ã‚’æ»‘ã‚‰ã‹ã«
                ctx.shadowBlur = 10; ctx.shadowColor = "#00FFFF"; // ç™ºå…‰ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ

                connections.forEach(([i, j]) => {
                    const p1 = smoothKeypoints[i];
                    const p2 = smoothKeypoints[j];
                    if (p1.score > 0.3 && p2.score > 0.3) {
                        ctx.beginPath();
                        ctx.moveTo((p1.x - lastSX) * sX, (p1.y - lastSY) * sY);
                        ctx.lineTo((p2.x - lastSX) * sX, (p2.y - lastSY) * sY);
                        ctx.stroke();
                    }
                });
                ctx.shadowBlur = 0; // é–¢ç¯€ã«ã¯ç™ºå…‰ã‚’ã‹ã‘ãªã„

                // 2. é–¢ç¯€ï¼ˆã‚ªãƒ¬ãƒ³ã‚¸ã®å¤§ããªä¸¸ï¼‰
                ctx.fillStyle = "#FF7700";
                smoothKeypoints.forEach((p, idx) => {
                    if (p.score > 0.3 && idx >= 5) {
                        const rx = (p.x - lastSX) * sX;
                        const ry = (p.y - lastSY) * sY;
                        ctx.beginPath(); 
                        ctx.arc(rx, ry, 15, 0, Math.PI * 2); // åŠå¾„15
                        ctx.fill();
                        ctx.strokeStyle = "#FFFFFF"; ctx.lineWidth = 4;
                        ctx.stroke();
                    }
                });
            }
            requestAnimationFrame(render);
        }

        document.getElementById('startBtn').onclick = () => { video.play(); render(); };

        document.getElementById('recBtn').onclick = (e) => {
            if (recorder?.state === 'recording') {
                recorder.stop();
                e.target.classList.remove('active');
                e.target.innerText = "ğŸ’¾ å‹•ç”»ã‚’ä¿å­˜";
            } else {
                chunks = [];
                const stream = canvas.captureStream(30);
                const mimeType = ["video/mp4;codecs=avc1", "video/webm"].find(t => MediaRecorder.isTypeSupported(t));
                recorder = new MediaRecorder(stream, { mimeType, videoBitsPerSecond: 5000000 }); // é«˜ç”»è³ªè¨­å®š
                recorder.ondataavailable = ev => chunks.push(ev.data);
                recorder.onstop = () => {
                    const blob = new Blob(chunks, { type: recorder.mimeType });
                    const url = URL.createObjectURL(blob);
                    const a = document.createElement('a'); a.href = url;
                    a.download = `pose_high_res_${Date.now()}.mp4`;
                    a.click();
                };
                recorder.start();
                e.target.classList.add('active'); e.target.innerText = "ğŸ”´ éŒ²ç”»åœæ­¢";
            }
        };

        init();
    </script>
</body>
</html>
